{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# url = 'https://www.boligsiden.dk/salgspris/solgt/alle/1/getdata?periode.from=2014-01-01&periode.to=2021-12-31&kommune=101'\n",
    "url = 'https://www.boligsiden.dk/salespriceresult/getdata?salgspristype=solgt&periode.from=2014-01-01&periode.to=2021-12-31&kommune=101&boligtype=alle&side=1'\n",
    "\n",
    "page = requests.get(url) \n",
    "# soup = BeautifulSoup(page.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the available information and storing in dataframe\n",
    "df = pd.DataFrame(page.json()['searchResult']['result']['propertySales'])\n",
    "df.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get a list over addresses\n",
    "address_mislabeled = df['addressLink'].to_list()\n",
    "address = []\n",
    "\n",
    "for i in range(len(address_mislabeled)):\n",
    "    address.append(address_mislabeled[i].replace(\"~\",\"\"))\n",
    "\n",
    "# print(address_mislabeled[0:3])\n",
    "# print(address[0:3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(address[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_url(address):\n",
    "    url =  f\"https://www.boligsiden.dk{address}\"\n",
    "    return url\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "add = address[0]\n",
    "url = get_url(add)\n",
    "\n",
    "response = requests.get(url) \n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data = soup.find_all('div', {'id':'dynamicText'})\n",
    "data = soup.find_all('div', {'class':'u-w-full u-w-1/2@sm u-pl-4 u-pr-6'})\n",
    "data[0]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}