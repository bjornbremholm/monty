{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Project Notebook\n",
    "\n",
    "### Authors: \n",
    "### Bjørn Bremholm\n",
    "### Laura Zeeper\n",
    "### Christoffer Gade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warning\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\n",
    "\n",
    "# Text analysis\n",
    "import nltk # NLTK: A basic, popular NLP package. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sentida import Sentida\n",
    "\n",
    "\n",
    "# Header to be used in request (contact info)\n",
    "header = {'Contact' : 'Christofferfoldager@gmail.com'}\n",
    "\n",
    "# \n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Section - Gather list of twitter accounts \n",
    "\n",
    "Description: In this section we will collect a dataframe containing infomation of danish MPs including their twitter accounts...\n",
    "\n",
    "Websites: \n",
    "1. https://www.ft.dk/da/medlemmer/mandatfordelingen - used to collect parties and the official MP's of each party\n",
    "2. https://filip.sdu.dk/twitter/politikere/ - used to collect the twitter accounts for each MP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Color</th>\n",
       "      <th>AddressLink</th>\n",
       "      <th>Members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>/searchResults.aspx?sortedDescending=false&amp;par...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Venstre (V)</td>\n",
       "      <td>Blue</td>\n",
       "      <td>/searchResults.aspx?sortedDescending=false&amp;par...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dansk Folkeparti (DF)</td>\n",
       "      <td>Blue</td>\n",
       "      <td>/searchResults.aspx?sortedDescending=false&amp;par...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Socialistisk Folkeparti (SF)</td>\n",
       "      <td>Red</td>\n",
       "      <td>/searchResults.aspx?sortedDescending=false&amp;par...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radikale Venstre (RV)</td>\n",
       "      <td>Red</td>\n",
       "      <td>/searchResults.aspx?sortedDescending=false&amp;par...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Party Color  \\\n",
       "0         Socialdemokratiet (S)   Red   \n",
       "1                   Venstre (V)  Blue   \n",
       "2         Dansk Folkeparti (DF)  Blue   \n",
       "3  Socialistisk Folkeparti (SF)   Red   \n",
       "4         Radikale Venstre (RV)   Red   \n",
       "\n",
       "                                         AddressLink Members  \n",
       "0  /searchResults.aspx?sortedDescending=false&par...      49  \n",
       "1  /searchResults.aspx?sortedDescending=false&par...      39  \n",
       "2  /searchResults.aspx?sortedDescending=false&par...      16  \n",
       "3  /searchResults.aspx?sortedDescending=false&par...      15  \n",
       "4  /searchResults.aspx?sortedDescending=false&par...      14  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the address link of each party\n",
    "url = 'https://www.ft.dk/da/medlemmer/mandatfordelingen'\n",
    "\n",
    "header['Info'] = 'Collecting a list of MP for research project'\n",
    "page = requests.get(url, verify=False, headers=header)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Get the links\n",
    "data = soup.find_all('table')[0]\n",
    "aref = data.find_all('a')\n",
    "member_nr = data.find_all('div', {'class':'member-container'})\n",
    "\n",
    "# Create a list with all relevant infomation \n",
    "Parties = []\n",
    "\n",
    "# defining red and blue \n",
    "Red = ['Socialdemokratiet (S)','Socialistisk Folkeparti (SF)','Radikale Venstre (RV)','Enhedslisten (EL)','Alternativet (ALT)']\n",
    "Blue = ['Det Konservative Folkeparti (KF)', 'Venstre (V)', 'Dansk Folkeparti (DF)', 'Det Konservative Folkeparti (KF)', 'Liberal Alliance (LA)', 'Nye Borgerlige (NB)', 'Kristendemokraterne (KD)']\n",
    "\n",
    "for i in range(len(aref)):\n",
    "    if aref[i].text in Red:\n",
    "        Color = 'Red'\n",
    "    elif aref[i].text in Blue:\n",
    "        Color = 'Blue'\n",
    "    else:\n",
    "        Color = None\n",
    "    Parties.append([aref[i].text,Color, aref[i].get('href'),member_nr[i].text])\n",
    "\n",
    "# Creates a Dataframe    \n",
    "df_Parties = pd.DataFrame(Parties, columns=['Party','Color','AddressLink','Members'])\n",
    "df_Parties.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Color</th>\n",
       "      <th>MP</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Middel Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ida Auken</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Ida</td>\n",
       "      <td>Auken</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trine Bramsen</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Trine</td>\n",
       "      <td>Bramsen</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bjørn Brandenborg</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Bjørn</td>\n",
       "      <td>Brandenborg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeppe Bruus</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Jeppe</td>\n",
       "      <td>Bruus</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morten Bødskov</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Morten</td>\n",
       "      <td>Bødskov</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                  Party Color                     MP  \\\n",
       "0          Ida Auken  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "1      Trine Bramsen  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "2  Bjørn Brandenborg  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "3        Jeppe Bruus  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "4     Morten Bødskov  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "\n",
       "  First Name    Last Name Middel Name  \n",
       "0        Ida        Auken              \n",
       "1      Trine      Bramsen              \n",
       "2      Bjørn  Brandenborg              \n",
       "3      Jeppe        Bruus              \n",
       "4     Morten      Bødskov              "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the names of each MP \n",
    "ID_list = []\n",
    "\n",
    "for i in range(len(df_Parties)): # Loop for each party\n",
    "    Party = df_Parties['Party'][i]\n",
    "    Color = df_Parties['Color'][i]\n",
    "\n",
    "    #Get the relevant party page\n",
    "    link = df_Parties['AddressLink'][i]\n",
    "    url = f'http://ft.dk{link}&page=1&sortedBy=&pageSize=50'\n",
    "    # time.sleep(1)\n",
    "    page = requests.get(url, verify=False, headers=header)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Get the names \n",
    "    tables = soup.find_all('tr',{'tabindex':0})\n",
    "\n",
    "    for i in range(len(tables)): # Loop for each member of the given party \n",
    "        FirstName = tables[i].find_all('td')[1].text\n",
    "        LastName = tables[i].find_all('a')[0].text\n",
    "        Name = FirstName + ' ' + LastName\n",
    "        MP = tables[i].find_all('td')[4].text\n",
    "\n",
    "        # Create a first, last and middle name (for use in merge)\n",
    "        Name_list = re.findall('\\w+',Name)\n",
    "        First_Name = Name_list[0]\n",
    "        Last_Name = Name_list[-1]\n",
    "        Middel_Name = ' '.join(Name_list[1:-1])\n",
    "\n",
    "        ID_list.append([Name,Party,Color,MP,First_Name,Last_Name,Middel_Name])\n",
    "\n",
    "df_Name = pd.DataFrame(ID_list, columns=['Name','Party','Color','MP','First Name','Last Name','Middel Name'])\n",
    "\n",
    "# Give color to the people out of party\n",
    "Red_Name = ['Susanne Zimmer','Sikandar Siddique','Uffe Elbæk'] \n",
    "Blue_Name = ['Simon Emil Ammitzbøll-Bille', 'Lars Løkke Rasmussen', 'Orla Østerby', 'Inger Støjberg']\n",
    "\n",
    "df_Name['Color'] = np.where((df_Name['Name'].isin(Red_Name)),'Red',df_Name['Color'])\n",
    "df_Name['Color'] = np.where((df_Name['Name'].isin(Blue_Name)),'Blue',df_Name['Color'])\n",
    "\n",
    "df_Name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Twitter_id</th>\n",
       "      <th>Følgere</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Middel Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margrethe Vestager</td>\n",
       "      <td>@vestager</td>\n",
       "      <td>295.359</td>\n",
       "      <td>Margrethe</td>\n",
       "      <td>Vestager</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lars Løkke Rasmussen</td>\n",
       "      <td>@larsloekke</td>\n",
       "      <td>198.367</td>\n",
       "      <td>Lars</td>\n",
       "      <td>Rasmussen</td>\n",
       "      <td>Løkke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pernille Skipper</td>\n",
       "      <td>@PSkipperEL</td>\n",
       "      <td>82.902</td>\n",
       "      <td>Pernille</td>\n",
       "      <td>Skipper</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ida Auken</td>\n",
       "      <td>@IdaAuken</td>\n",
       "      <td>73.928</td>\n",
       "      <td>Ida</td>\n",
       "      <td>Auken</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kristian Jensen</td>\n",
       "      <td>@Kristian_Jensen</td>\n",
       "      <td>62.954</td>\n",
       "      <td>Kristian</td>\n",
       "      <td>Jensen</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name        Twitter_id  Følgere First Name  Last Name  \\\n",
       "0    Margrethe Vestager         @vestager  295.359  Margrethe   Vestager   \n",
       "1  Lars Løkke Rasmussen       @larsloekke  198.367       Lars  Rasmussen   \n",
       "2      Pernille Skipper       @PSkipperEL   82.902   Pernille    Skipper   \n",
       "3             Ida Auken         @IdaAuken   73.928        Ida      Auken   \n",
       "4       Kristian Jensen  @Kristian_Jensen   62.954   Kristian     Jensen   \n",
       "\n",
       "  Middel Name  \n",
       "0              \n",
       "1       Løkke  \n",
       "2              \n",
       "3              \n",
       "4              "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the twitter accounts \n",
    "url = 'https://filip.sdu.dk/twitter/politikere/'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "data = soup.find_all('div', {'class':'col-md-6 show_tweet show_user'}) # Finds the list of all politicians twitter account\n",
    "\n",
    "Twitter_list = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    info_i = data[i].find_all('div', {'class':'media-body'})\n",
    "    twitter_id = info_i[0].find('h3').text.split()\n",
    "    person_id = info_i[0].find('small').text.split(' \\nmed ')\n",
    "\n",
    "    Name = person_id[0]\n",
    "    Tag = twitter_id[1]\n",
    "    Følgere = re.search('[0-9.]+[0-9]|\\d', person_id[1]).group()\n",
    "\n",
    "    # Create a first, last and middle name (for merge purpose)\n",
    "    Name_list = re.findall('\\w+',Name)\n",
    "    First_Name = Name_list[0]\n",
    "    Last_Name = Name_list[-1]\n",
    "    Middel_Name = ' '.join(Name_list[1:-1])\n",
    "\n",
    "    Twitter_list.append([Name,Tag,Følgere, First_Name, Last_Name,Middel_Name])\n",
    "\n",
    "df_Twitter_id = pd.DataFrame(Twitter_list, columns=['Name','Twitter_id','Følgere','First Name','Last Name','Middel Name'])\n",
    "df_Twitter_id.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are missing: 32 twitter accounts\n"
     ]
    }
   ],
   "source": [
    "# First merge effort\n",
    "def merge_df(df_name,df_twitter):\n",
    "    # Merge on first and last name \n",
    "    df_new = pd.merge(df_name,df_twitter[['First Name', 'Last Name','Twitter_id','Følgere']],  how='left', on=['First Name','Last Name'])\n",
    "    # Merge on first and middel name\n",
    "    df_new1 = pd.merge(df_name, df_twitter[['First Name', 'Last Name','Twitter_id','Følgere']],  how='left', left_on = ['First Name','Middel Name'], right_on=['First Name', 'Last Name'])\n",
    "\n",
    "    df_new['Twitter_id'] = df_new['Twitter_id'].fillna(df_new1['Twitter_id'])\n",
    "    df_new['Følgere'] = df_new['Følgere'].fillna(df_new1['Følgere'])\n",
    "\n",
    "    # We will still miss a few Twitter_id (human error or no twitter account)\n",
    "    df_new.replace(float('NaN'),'None',inplace=True)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "df_info = merge_df(df_Name,df_Twitter_id)\n",
    "twitter_missing = len(df_info.loc[df_info['Twitter_id'] == 'None'])\n",
    "print ('We are missing: '+ str(twitter_missing) + ' twitter accounts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "manuel_handles = {'Kaare Dybvad Bek':'@KaareDybvad', 'Karin Gaardsted' : '@KarinGaardsted', 'Ane Halsboe-Jørgensen':'@AneHalsboe', \n",
    "                    'Christian Rabjerg Madsen' : '@RabjergMadsen', 'Lars Aslan Rasmussen':'@lars_aslan', 'Pernille Rosenkrantz-Theil' : '@RosenkrantzT',\n",
    "                    'Kasper Roug':'@KasperRoug', 'Mads  Fuglede':'@madsfuglede', 'Peter Juel-Jensen':'@PeterJuelJensen',\n",
    "                    'Stén Knuth':'@Sten_Knuth',  'Lars Christian Lilleholt':'@larsclilleholt', 'Kristian Pihl Lorentzen':'@kplorentzen',\n",
    "                    'Torsten Schack Pedersen':'@Torstenschack', 'Lise Bech':'@LiseBech', 'Jens Henrik Thulesen Dahl':'@JThulesen', \n",
    "                    'Mette Hjermind Dencker':'@dfmehd_mette', 'Kirsten Normann Andersen':'@KirstenNormann', 'Karina Lorentzen Dehnhardt':'@MF_K_Lorentzen',\n",
    "                    'Charlotte Broman Mølbæk':'@charlottebroman', 'Rasmus Nordqvist':'@rasmusnordqvist', 'Trine Torp':'@TrineTorp', \n",
    "                    'Sofie Carsten Nielsen':'@sofiecn', 'Rasmus Helveg Petersen':'@rasmushelveg', 'Victoria Velasquez':'@VictoriaV_EL', \n",
    "                    'Katarina Ammitzbøll':'@Ammitzboell_K', 'Brigitte Klintskov Jerkel':'@JerkelK', 'Aki-Matilda Høegh-Dam': '@AkiMati_Siumut',\n",
    "                    'Sjúrður Skaale': '@SjurSkaale', 'Uffe Elbæk':'@uffeelbaek'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are missing: 16 twitter accounts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Color</th>\n",
       "      <th>MP</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Middel Name</th>\n",
       "      <th>Twitter_id</th>\n",
       "      <th>Følgere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ida Auken</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Ida</td>\n",
       "      <td>Auken</td>\n",
       "      <td></td>\n",
       "      <td>@IdaAuken</td>\n",
       "      <td>73.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trine Bramsen</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Trine</td>\n",
       "      <td>Bramsen</td>\n",
       "      <td></td>\n",
       "      <td>@Trinebramsen</td>\n",
       "      <td>13.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bjørn Brandenborg</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Bjørn</td>\n",
       "      <td>Brandenborg</td>\n",
       "      <td></td>\n",
       "      <td>@BjBrandenborg</td>\n",
       "      <td>2.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeppe Bruus</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Jeppe</td>\n",
       "      <td>Bruus</td>\n",
       "      <td></td>\n",
       "      <td>@JeppeBruus</td>\n",
       "      <td>4.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morten Bødskov</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>Morten</td>\n",
       "      <td>Bødskov</td>\n",
       "      <td></td>\n",
       "      <td>@mfMorten</td>\n",
       "      <td>15.328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                  Party Color                     MP  \\\n",
       "0          Ida Auken  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "1      Trine Bramsen  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "2  Bjørn Brandenborg  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "3        Jeppe Bruus  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "4     Morten Bødskov  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "\n",
       "  First Name    Last Name Middel Name      Twitter_id Følgere  \n",
       "0        Ida        Auken                   @IdaAuken  73.928  \n",
       "1      Trine      Bramsen               @Trinebramsen  13.517  \n",
       "2      Bjørn  Brandenborg              @BjBrandenborg   2.278  \n",
       "3      Jeppe        Bruus                 @JeppeBruus   4.069  \n",
       "4     Morten      Bødskov                   @mfMorten  15.328  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in manuel_handles:\n",
    "    index = df_info[df_info['Name'] == key].index\n",
    "    df_info.iloc[index[0],7] = manuel_handles[key]\n",
    "\n",
    "twitter_missing = len(df_info.loc[df_info['Twitter_id'] == 'None'])\n",
    "print ('We are missing: '+ str(twitter_missing) + ' twitter accounts')\n",
    "df_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Color</th>\n",
       "      <th>MP</th>\n",
       "      <th>Twitter_id</th>\n",
       "      <th>Følgere</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ida Auken</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>@IdaAuken</td>\n",
       "      <td>73.928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trine Bramsen</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>@Trinebramsen</td>\n",
       "      <td>13.517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bjørn Brandenborg</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>@BjBrandenborg</td>\n",
       "      <td>2.278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeppe Bruus</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>@JeppeBruus</td>\n",
       "      <td>4.069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morten Bødskov</td>\n",
       "      <td>Socialdemokratiet (S)</td>\n",
       "      <td>Red</td>\n",
       "      <td>Medlem af Folketinget</td>\n",
       "      <td>@mfMorten</td>\n",
       "      <td>15.328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                  Party Color                     MP  \\\n",
       "0          Ida Auken  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "1      Trine Bramsen  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "2  Bjørn Brandenborg  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "3        Jeppe Bruus  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "4     Morten Bødskov  Socialdemokratiet (S)   Red  Medlem af Folketinget   \n",
       "\n",
       "       Twitter_id Følgere  y  \n",
       "0       @IdaAuken  73.928  0  \n",
       "1   @Trinebramsen  13.517  0  \n",
       "2  @BjBrandenborg   2.278  0  \n",
       "3     @JeppeBruus   4.069  0  \n",
       "4       @mfMorten  15.328  0  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_info.copy()\n",
    "\n",
    "# Dropping columns\n",
    "Columns = ['First Name', 'Last Name','Middel Name']\n",
    "df_data = df_data.drop(columns=Columns, axis=1)\n",
    "\n",
    "# Dropping those without twitter_id\n",
    "df_data = df_data[df_data.Twitter_id != 'None']\n",
    "\n",
    "# Dropping MPs from greenland and faroe islands\n",
    "df_data = df_data[df_data.Color != 'None']\n",
    "\n",
    "# Reindex\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "\n",
    "# Create y binary\n",
    "df_data['y'] = np.where((df_data['Color'] == 'Blue'),1,0)\n",
    "\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Collecting Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get authentication by twitter and access to their API \n",
    "consumer_key = 'k5bWZZyOPUwPYs1BCpSEoBNHQ'\n",
    "consumer_secret = 'g6HxSQyhhBuZjwWyGcNornDFL7wkmz4wAabdJqqnJyk10T3Q6G'\n",
    "callback_url = 'oob'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret, callback_url)\n",
    "\n",
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "except tweepy.TweepError:\n",
    "    print('Error! Failed to get request token.')\n",
    "\n",
    "webbrowser.open(redirect_url)\n",
    "\n",
    "user_pin_input = input('What is the pin value? ')\n",
    "auth.get_access_token(user_pin_input)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function gathering the tweets from a specific user/handle\n",
    "def extract_tweets(handle,name):\n",
    "\n",
    "    # Input: Handle/user (e.g. @JeppeKofod) which is used to collect tweets\n",
    "    #\n",
    "    # Output: Dataframe containing tweets with attaching information \n",
    "\n",
    "    # tweets = api.user_timeline(screen_name=handle,count=40,exclude_replies=True,include_rts=False,tweet_mode=\"extended\") \n",
    "    tweets = tweepy.Cursor(api.user_timeline,screen_name = handle, tweet_mode='extended', include_rts=False, exclude_replies=True).items()\n",
    "    tweets_data = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        date = tweet.created_at\n",
    "        author = tweet.author.screen_name\n",
    "        likes = tweet.favorite_count\n",
    "        retweets = tweet.retweet_count\n",
    "        source = tweet.source\n",
    "        text = tweet.full_text\n",
    "        lang = tweet.lang\n",
    "\n",
    "        tweets_data.append([date,author,name,text,lang,likes,retweets,source])\n",
    "\n",
    "    df_tweets = pd.DataFrame(tweets_data, columns=['Date','Author','Name','Tweet','Language','Likes','Retweets','Source'])\n",
    "    return df_tweets \n",
    "\n",
    "# Get dataframe of tweets and updated df_data\n",
    "def get_tweets_df(df):\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df_out = pd.DataFrame()\n",
    "    tweet_count = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        # Find user\n",
    "        user = df['Twitter_id'][i]\n",
    "        name = df['Name'][i]\n",
    "        \n",
    "        # Collects tweets from user\n",
    "        df_tweets = extract_tweets(user,name)\n",
    "        df_out = df_out.append(df_tweets)\n",
    "\n",
    "        # Collect total of tweets\n",
    "        tweet_count.append(len(df_tweets))\n",
    "        \n",
    "        # Request limit time sleeper\n",
    "        time.sleep(90)\n",
    "    \n",
    "    df_out = df_out.reset_index(drop=True)\n",
    "    df['Tweet Count'] = tweet_count\n",
    "\n",
    "    return df_out,df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-340-0f6344b62595>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-340-0f6344b62595>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    dont fucking run this\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "dont fucking run this\n",
    "######################\n",
    "df1 = df_data.copy()\n",
    "\n",
    "# Get twitter data\n",
    "df_twitter_data, df_Name_list = get_tweets_df(df1)\n",
    "\n",
    "# Saving the dataframes\n",
    "df_Name_list.to_csv('Name_id_Final.csv')\n",
    "df_twitter_data.to_csv('Twitter_data_Final.csv')\n",
    "\n",
    "# Print\n",
    "df_twitter_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Procession text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will collect our saved data\n",
    "df_Name_id_list = pd.read_csv('Name_id_Final.csv')\n",
    "df_twitter_data = pd.read_csv('Twitter_data_Final.csv')\n",
    "\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People with no Tweets: ['Nick Hækkerup', 'Jan Johansen', 'Bjarne Laustsen']\n",
      "People who enters more than once: ['Søren Egge Rasmussen']\n"
     ]
    }
   ],
   "source": [
    "# Mergeing the two dataframes \n",
    "\n",
    "# Dropping people with out tweets\n",
    "df_Name_id_list.sort_values('Tweet Count')\n",
    "a = df_Name_id_list[df_Name_id_list['Tweet Count'] == 0]['Name'].to_list()\n",
    "print('People with no Tweets: ' + str(a))\n",
    "df_Name_id_list = df_Name_id_list[~df_Name_id_list['Name'].isin(a)]\n",
    "\n",
    "# Dropping duplicates\n",
    "dup = df_Name_id_list[df_Name_id_list.duplicated('Name')]['Name'].to_list()\n",
    "print('People who enters more than once: ' + str(dup))\n",
    "df_Name_id_list = df_Name_id_list.drop_duplicates('Name',keep='first')\n",
    "\n",
    "# Merge certain columns\n",
    "Col_Name = ['Name','Party','MP','Color','Twitter_id','Følgere','Tweet Count','y']\n",
    "Col_Tweet = ['Date','Name','Tweet','Language','Likes','Retweets','Source']\n",
    "\n",
    "# Merge\n",
    "df_main_preprocessed = pd.merge(df_twitter_data[Col_Tweet],df_Name_id_list[Col_Name],how='left',on='Name')\n",
    "\n",
    "# Remove english tweets\n",
    "a = len(df_main_preprocessed)\n",
    "df_main_preprocessed = df_main_preprocessed[df_main_preprocessed['Language'] != 'en'].reset_index(drop=True)\n",
    "print('English tweets removed: ' + str(a-len(df_main_preprocessed)))\n",
    "\n",
    "# Print df\n",
    "df_main_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the individual tweet\n",
    "def preprocess(text):\n",
    "    \n",
    "    text = re.sub('http\\S*','', text) # remove links\n",
    "\n",
    "    if len(text) in [0,1,2,3,4,5,6] : return ['None']*3\n",
    "\n",
    "    SV = Sentida()\n",
    "    sentiment_mean_score = SV.sentida(text, output='mean', normal=True)\n",
    "\n",
    "    text = re.sub(r'[^\\w\\#\\s]','', text) \n",
    "    text = re.sub('\\s[0-9]','', text) \n",
    "\n",
    "    tokens = nltk.TweetTokenizer().tokenize(text.lower()) # Keeps hashtag\n",
    "\n",
    "    stop_words_list = nltk.corpus.stopwords.words(\"danish\")\n",
    "    lemmas = [i for i in tokens if i not in stop_words_list]\n",
    "\n",
    "    text_new = ' '.join(lemmas)\n",
    "\n",
    "    return lemmas, text_new, np.round(sentiment_mean_score,2)\n",
    "\n",
    "# Function that will process every tweet\n",
    "def process_tweets_data(df):\n",
    "    \n",
    "    info_list = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        text = df['Tweet'][i]\n",
    "        # print(i)\n",
    "        stems, final_text, sentiment_mean = preprocess(text)\n",
    "        \n",
    "        # Gather infomation to df\n",
    "        Date = df['Date'][i]\n",
    "        Name = df['Name'][i]\n",
    "        Language = df['Language'][i]\n",
    "        Likes = df['Likes'][i]\n",
    "        Retweets = df['Retweets'][i]\n",
    "        Følgere = df['Følgere'][i]\n",
    "        Tweet_count = df['Tweet Count'][i]\n",
    "        y = df['y'][i]\n",
    "        Party = df['Party'][i]\n",
    "\n",
    "        # Append list\n",
    "        info_list.append([Date, Name, Party ,Følgere,Tweet_count,text,Language,Likes,Retweets,stems,final_text,sentiment_mean,y])\n",
    "    \n",
    "    # Create columns names\n",
    "    Col_name = ['Date','Name','Party','Følgere','Tweet Count','Tweet','la','Likes','Retweets','Stems','Final Text','Sentiment','y']\n",
    "\n",
    "    # Create new dataframe\n",
    "    df_out = pd.DataFrame(info_list, columns=Col_name)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    # lemmas = text.lower()\n",
    "    text = re.sub('https:[\\s\\S]*$','', text) # remove links\n",
    "    text = re.sub(r'[^\\w\\#\\s]','', text) # should we leave hashtag or not\n",
    "\n",
    "    tokens = nltk.TweetTokenizer().tokenize(text.lower())\n",
    "\n",
    "    # tokens = nltk.word_tokenize(text.lower())\n",
    "    # wnl = nltk.WordNetLemmatizer()\n",
    "    # lemmas = [wnl.lemmatize(t) for t in tokens]\n",
    "\n",
    "    stop_words_list = nltk.corpus.stopwords.words(\"danish\")\n",
    "    lemmas = [i for i in tokens if i not in stop_words_list]\n",
    "\n",
    "    return lemmas # return a list of stems/lemmas\n",
    "\n",
    "\n",
    "def process_tweets_text(df):\n",
    "\n",
    "    tweet_process = []\n",
    "\n",
    "\n",
    "    for i in range(len(df['Tweet'])):\n",
    "        text = df['Tweet'][i]\n",
    "        Processed_text = preprocess(text)\n",
    "        Final_text = ' '.join(Processed_text)\n",
    "\n",
    "        tweet_process.append([df['Date'][i],df['Name'][i],text,Processed_text,Final_text,df['Language'][i]])\n",
    "\n",
    "    df_out = pd.DataFrame(tweet_process, columns=['Date','Name','text','Tweet Processed','Final_text','Language'])\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the text process\n",
    "text= df_main_preprocessed['Tweet'][4]\n",
    "\n",
    "results = preprocess(text)\n",
    " \n",
    "# Text\n",
    "print('Old text: \\n' + text  + '\\n')\n",
    "print('New text (text): ' + str(len(results[1])) + ' list length \\n' + str(results[1]) + '\\n')\n",
    "print('New text (Stems): ' + str(len(results[0])) + ' list length \\n' + str(results[0]) + '\\n')\n",
    "\n",
    "# Sentiment scores\n",
    "print('The mean sentiment score is: ' + str(results[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a main dataframe (approx = 6-700 sec.)\n",
    "df_main_backup = process_tweets_data(df_main_preprocessed)\n",
    "df_main = df_main_backup.copy()\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows with no final text (pictures and emoji)\n",
    "df_main_done = df_main[df_main['Stems']!='None'].reset_index(drop=True)\n",
    "\n",
    "# Setting dates to after 2015-01-01\n",
    "df_main_done['Date'] = pd.to_datetime(df_main_done['Date'],format = '%Y-%m-%d %H:%M:%S')\n",
    "df_main_done = df_main_done.loc[df_main_done['Date'] >= '2015-1-01'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes (Election-periods, the 6-month preelection, corona period)\n",
    "# Total \n",
    "df_blue = df_main_done[df_main_done['y']==1]\n",
    "df_red  = df_main_done[df_main_done['y']==0]\n",
    "\n",
    "xb = np.array(df_blue['Sentiment'].to_list())\n",
    "xr = np.array(df_red['Sentiment'].to_list())\n",
    "\n",
    "# 2015 election period\n",
    "df_2017_valg = df_main_done.loc[df_main_done['Date'] >= '2015-06-18'].reset_index(drop=True)\n",
    "df_2017_valg = df_2017_valg.loc[df_2017_valg['Date'] <= '2019-06-05'].reset_index(drop=True)\n",
    "\n",
    "df_blue_2017 = df_2017_valg[df_2017_valg['y']==1]\n",
    "df_red_2017  = df_2017_valg[df_2017_valg['y']==0]\n",
    "\n",
    "xb_2017 = np.array(df_blue_2017['Sentiment'].to_list())\n",
    "xr_2017 = np.array(df_red_2017['Sentiment'].to_list())\n",
    "\n",
    "\n",
    "# 2019 election period\n",
    "df_2019_valg = df_main_done.loc[df_main_done['Date'] >= '2019-06-05'].reset_index(drop=True)\n",
    "\n",
    "df_blue_2019 = df_2019_valg[df_2019_valg['y']==1]\n",
    "df_red_2019  = df_2019_valg[df_2019_valg['y']==0]\n",
    "\n",
    "xb_2019 = np.array(df_blue_2019['Sentiment'].to_list())\n",
    "xr_2019 = np.array(df_red_2019['Sentiment'].to_list())\n",
    "\n",
    "# 2015 election pre period\n",
    "df_2017_valg_pre = df_main_done.loc[df_main_done['Date'] <= '2015-06-18'].reset_index(drop=True)\n",
    "df_2017_valg_pre = df_2017_valg_pre.loc[df_2017_valg_pre['Date'] >= '2015-01-01'].reset_index(drop=True)\n",
    "\n",
    "df_blue_2017_pre = df_2017_valg_pre[df_2017_valg_pre['y']==1]\n",
    "df_red_2017_pre  = df_2017_valg_pre[df_2017_valg_pre['y']==0]\n",
    "\n",
    "xb_2017_pre = np.array(df_blue_2017_pre['Sentiment'].to_list())\n",
    "xr_2017_pre = np.array(df_red_2017_pre['Sentiment'].to_list())\n",
    "\n",
    "# 2019 election pre period\n",
    "df_2019_valg_pre = df_main_done.loc[df_main_done['Date'] <= '2019-06-05'].reset_index(drop=True)\n",
    "df_2019_valg_pre = df_main_done.loc[df_main_done['Date'] >= '2019-01-01'].reset_index(drop=True)\n",
    "\n",
    "df_blue_2019_pre = df_2019_valg_pre[df_2019_valg_pre['y']==1]\n",
    "df_red_2019_pre  = df_2019_valg_pre[df_2019_valg_pre['y']==0]\n",
    "\n",
    "xb_2019_pre = np.array(df_blue_2019_pre['Sentiment'].to_list())\n",
    "xr_2019_pre = np.array(df_red_2019_pre['Sentiment'].to_list())\n",
    "\n",
    "# corona period\n",
    "df_corona = df_main_done.loc[df_main_done['Date'] >= '2020-03-11'].reset_index(drop=True)\n",
    "\n",
    "df_blue_corona = df_corona[df_corona['y']==1]\n",
    "df_red_corona  = df_corona[df_corona['y']==0]\n",
    "\n",
    "xb_corona = np.array(df_blue_corona['Sentiment'].to_list())\n",
    "xr_corona = np.array(df_red_corona['Sentiment'].to_list())\n",
    "\n",
    "\n",
    "# Create Plots \n",
    "\n",
    "fig = plt.figure(figsize=(8, 4), dpi=200)\n",
    "fig.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "ax_Total = fig.add_subplot(2,3,1)\n",
    "ax_Total.hist(xb,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_Total.hist(xr,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_Total.axvline(0,color='black',linestyle='--',linewidth=0.5)\n",
    "ax_Total.set_title('Total',size = 'small')\n",
    "\n",
    "ax_2019 = fig.add_subplot(2,3,2)\n",
    "ax_2019.hist(xb_2019,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2019.hist(xr_2019,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2019.axvline(0,color='black',linestyle='--',linewidth=0.5)\n",
    "ax_2019.set_title('5. June 2019 - Present',size='small')\n",
    "\n",
    "ax_2017 = fig.add_subplot(2,3,3)\n",
    "ax_2017.hist(xb_2017,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2017.hist(xr_2017,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2017.axvline(0,color='black',linestyle='--',linewidth=0.5)\n",
    "ax_2017.set_title('18 June 2015 - 5. June 2019',size='small')\n",
    "\n",
    "ax_Corona = fig.add_subplot(2,3,4)\n",
    "ax_Corona.hist(xb_corona,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_Corona.hist(xr_corona,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_Corona.axvline(0,color='black',linestyle='--',linewidth=0.5)\n",
    "ax_Corona.set_title('Corona',size = 'small')\n",
    "\n",
    "ax_2019_pre = fig.add_subplot(2,3,5)\n",
    "ax_2019_pre.hist(xb_2019_pre,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2019_pre.hist(xr_2019_pre,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2019_pre.axvline(0,color='black',linestyle='--',linewidth=0.5)\n",
    "ax_2019_pre.set_title('1. January 2019 - 5. June 2019',size='small')\n",
    "\n",
    "ax_2017_pre = fig.add_subplot(2,3,6)\n",
    "ax_2017_pre.hist(xb_2017_pre,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2017_pre.hist(xr_2017_pre,bins=50, histtype= 'stepfilled',alpha= 0.3,density=True)\n",
    "ax_2017_pre.axvline(0,color='black',linestyle='--',linewidth=0.5)\n",
    "ax_2017_pre.set_title('1. January 2015 - 18. June 2015',size='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 6 month running average sentiment score across the blocks\n",
    "def six_month_average(df):\n",
    "    df_blue = df[df['y']==1]\n",
    "    df_red = df[df['y']==0]\n",
    "    blue_sentiment_average_month = []\n",
    "    red_sentiment_average_month = []\n",
    "    dates = []\n",
    "    \n",
    "\n",
    "    date_list = df['Date'].sort_values().reset_index(drop=True).to_list()\n",
    "    year, month = date_list[0].year, date_list[0].month\n",
    "    end_year, end_month = date_list[-1].year, date_list[-1].month\n",
    "\n",
    "    while (year < end_year) or (month < end_month):\n",
    "        if month > 12: # execute next year\n",
    "            year = year + 1 # Dont touch\n",
    "            month = 1 # Dont touch\n",
    "        else:\n",
    "            date = str(year) + '-' + str(month) + '-01'\n",
    "            if month == 12:\n",
    "                date_next = str(year+1) + '-1-01'\n",
    "            else:\n",
    "                date_next = str(year) + '-' + str(month+1) + '-01'\n",
    "\n",
    "            dates.append(date)\n",
    "            \n",
    "            df_blue_month = df_blue.loc[df_blue['Date'] >= date].reset_index(drop=True)\n",
    "            df_blue_month = df_blue_month.loc[df_blue_month['Date'] < date_next].reset_index(drop=True)\n",
    "            df_red_month = df_red.loc[df_red['Date'] >= date].reset_index(drop=True)\n",
    "            df_red_month = df_red_month.loc[df_red_month['Date'] < date_next].reset_index(drop=True)\n",
    "\n",
    "            blue_sentiment_average_month.append(df_blue_month['Sentiment'].mean())\n",
    "            red_sentiment_average_month.append(df_red_month['Sentiment'].mean())\n",
    "\n",
    "            \n",
    "            month = month +1 # Dont touch\n",
    "\n",
    "    blue_moving_average = np.convolve(np.array(blue_sentiment_average_month), np.ones(7), 'valid')/7\n",
    "    red_moving_average = np.convolve(np.array(red_sentiment_average_month), np.ones(7), 'valid')/7\n",
    "         \n",
    "\n",
    "    return blue_moving_average, red_moving_average, blue_sentiment_average_month, red_sentiment_average_month, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = six_month_average(df_main_done)\n",
    "dates = a[4][3:-3]\n",
    "\n",
    "\n",
    "fig1 = plt.figure(figsize=(6, 5), dpi=100)\n",
    "\n",
    "\n",
    "x_blue = np.array(np.arange(len(a[0])))\n",
    "y_blue = np.array(a[0])\n",
    "x_red = np.array(np.arange(len(a[1])))\n",
    "y_red = np.array(a[1])\n",
    "\n",
    "plt.xticks(x[::12], dates[::12],fontsize=8)\n",
    "\n",
    "plt.plot(x_blue, y_blue,color='blue')\n",
    "plt.plot(x_red, y_red,color='red')\n",
    "plt.title('Sentiment Score (7 month running average)')\n",
    "plt.axvline(2,linestyle = '--', linewidth = 1, color='black')\n",
    "plt.axvline(50,linestyle = '--', linewidth = 1, color='black',label='Election')\n",
    "plt.axvline(59,linestyle = ':', linewidth = 1, color='black',label='Corona')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(array):\n",
    "    info = []\n",
    "    obs = stats.describe(array).nobs\n",
    "    mean = stats.describe(array).mean\n",
    "    min = stats.describe(array).minmax[0]\n",
    "    max = stats.describe(array).minmax[1]\n",
    "    var = stats.describe(array).variance\n",
    "    skewness = stats.describe(array).skewness\n",
    "    kurtosis = stats.describe(array).kurtosis\n",
    "\n",
    "    info.append([obs,mean,var,min,max,skewness,kurtosis])\n",
    "    return info[0]\n",
    "\n",
    "\n",
    "db_total, dr_total = get_description(xb), get_description(xr)\n",
    "db_2019, dr_2019 = get_description(xb_2019), get_description(xr_2019)\n",
    "db_2017, dr_2017 = get_description(xb_2017), get_description(xr_2017)\n",
    "db_corona, dr_corona = get_description(xb_corona), get_description(xr_corona)\n",
    "db_2019_pre, dr_2019_pre = get_description(xb_2019_pre), get_description(xr_2019_pre)\n",
    "db_2017_pre, dr_2017_pre = get_description(xb_2017_pre), get_description(xr_2017_pre)\n",
    "\n",
    "time = np.array(['Blå (Total)','Rød (Total)','Blå (corona)','Rød (corona)','Blå (2019-nu)','Rød (2019-nu)','Blå (2019 pre election)','Rød (2019 pre election)','Blå (2015-2019)','Rød (2015-2019)','Blå (2015 pre election)','Rød (2015 pre election)'])\n",
    "df_info_sentiment = pd.DataFrame([db_total,dr_total,db_corona,dr_corona,db_2019,dr_2019,db_2019_pre, dr_2019_pre, db_2017,dr_2017,db_2017_pre,dr_2017_pre],columns=(['obs','mean','variance','min','max','skeness','kurtosis'])).set_index(time,drop=True)\n",
    "df_info_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(df):\n",
    "    \"\"\"\n",
    "    Function that finds every hashtag in the column 'Tweet' and count the appearances\n",
    "    \"\"\"\n",
    "    counter_hashtag = Counter()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        text = df['Tweet'][i]\n",
    "        find_h = re.findall('\\#\\S*',text)\n",
    "        new = Counter(find_h)\n",
    "        counter_hashtag = counter_hashtag + new\n",
    "    \n",
    "    df_out = pd.DataFrame(dict(counter_hashtag).items(), columns=['Word','Count'])\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_main_done.copy()\n",
    "\n",
    "text = text.loc[text['Date'] >= '2019-06-05'].reset_index(drop=True)\n",
    "\n",
    "# text = text.loc[text['Date'] >= '2020-03-11'].reset_index(drop=True)\n",
    "# text = text.loc[text['Date'] <= '2020-12-31'].reset_index(drop=True)\n",
    "\n",
    "df_hashtags_2019 = find_hashtags(text)\n",
    "\n",
    "df_hashtags_2019 = df_hashtags_2019.sort_values('Count',ascending=False).reset_index(drop=True)\n",
    "df_hashtags_2019[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new test dataframe for ML \n",
    "test = df_main_done.copy()\n",
    "\n",
    "list_of_words= df_hashtags_2019['Word'][0:20].to_list()\n",
    "\n",
    "pattern = '|'.join(list_of_words)\n",
    "\n",
    "df_test = test[test['Final Text'].str.contains(pattern)]\n",
    "df_test = df_test.loc[df_test['Date'] >= '2019-06-05'].reset_index(drop=True)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LONG TWEETS\n",
    "X, y = df_test['Final Text'], df_test['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,4), max_features = 200)\n",
    "\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.fit_transform(X_test)\n",
    "print(\"We have \" + str(np.round(sum(y_train)/len(y_train)*100,2)) + '% of blue tweets in our train')\n",
    "print(\"We have \" + str(np.round(sum(y_test)/len(y_test)*100,2)) + '% of blue tweets in our test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter = 1000, solver = 'saga', penalty ='l1', fit_intercept=True ).fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our testset is: ' + str(len(y_test)) + ' observation \\nTrue: ' + str(y_test.sum()) + ' Blue tweets' )\n",
    "a = y_pred == y_test\n",
    "print('We found: ' + str(y_pred.sum()) + ' Blue tweets \\nWe predicted: ' + str(np.round(a.mean()*100,2)) + ' % correct tweets overall')\n",
    "a = Counter(y_pred-y_test)\n",
    "\n",
    "print('\\nWe missed to predict: ' + str(a[-1]) + ' Tweets \\n\\nOf the predicted Blue (' + str(y_pred.sum()) + ') \\nCorrect prediction: ' + str(y_pred.sum()-a[1]) + '\\nWrong prediction: ' + str(a[1]))\n",
    "\n",
    "print('\\nOf the predicted Red (' + str(len(y_pred) - y_pred.sum()) + ') \\nCorrect prediction: ' + str(len(y_pred) - y_pred.sum()-a[-1]) + '\\nWrong prediction: ' + str(a[-1]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}